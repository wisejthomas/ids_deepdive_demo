{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf7d51e-9d0a-437c-8b6f-d402b5f3cc9b",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This worksheet, provides a range of fill in the blank, learning prompts and other activities to engage users in their initial steps within using Python within GCP. \n",
    "\n",
    "This worksheet is broken down into several core sections, corresponding with those sections covered within the demonstration. Please note, as section one explore the BigQuery Studio environment, coding questions will not be provided for this section, rather only prompts to encourage your user experience with the upcoming deep dive workshop. \n",
    "\n",
    "Please note, there is an accompanying Solutions Sheet, to provide the answers as needed!\n",
    "\n",
    "## Section 1: Navigating Data in BigQuery Studio \n",
    "\n",
    "Using the BigQuery Studio (and potentially going beyond the dataset we explored within the session), explore the metadata (variable names, previews etc) of various datasets available within the GCP environment. \n",
    "\n",
    "## Section 2a: Package Installation and Setup \n",
    "Run the following code, to prepare the environment and load in the relevant packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dda492-5198-48ae-b693-eaef8e34dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# here the package is bigframes https://pypi.org/project/bigframes/\n",
    "import sys\n",
    "!{sys.executable} -m pip install bigframes | grep -v 'already satisfied'\n",
    "\n",
    "import bigframes.pandas as bpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# import warnings filter & ignore all future warnings\n",
    "# this is for teaching purposes only, to avoid FutureWarnings to do with bigframe compiler implementation\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66293f0b-6a87-4191-b176-3764a950245b",
   "metadata": {},
   "source": [
    "## Section 3a: Load in Data\n",
    "Load in the Fire Brigade Data from GCP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc055f13-0e6f-468e-9194-c64b2cd46fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the Blanks\n",
    "\n",
    "# Load data from BigQuery\n",
    "query_or_table = \"bigquery-public-data.london_fire_brigade.---\" # [Insert the table name here]\n",
    "bq_df = bpd.read_gbq(---, use_cache=False) # [Insert Variable Name Here]\n",
    "\n",
    "# Double Check the column names \n",
    "list(---) # [Insert Read in GBQ Data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06a2c4-acc1-4776-b5f4-57418ab994df",
   "metadata": {},
   "source": [
    "## Section 3b: Using Magic Commands to Manipulate Data \n",
    "\n",
    "Complete the following magic command to explore the number of Outdoor Fires by Hour of Call made. This will produce a breakdown per hour of call, for the quantity of fires call outs which happened under the Outdoor Category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aac1d3-3d97-457b-8737-d176236a2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery hour_of_call_outdoorcategory\n",
    "SELECT\n",
    "    ----, # [Insert Variable here]\n",
    "    COUNT(DISTINCT incident_number) as incident_number_count\n",
    "FROM \n",
    "    ---- # [Insert Dataset]\n",
    "WHERE \n",
    "    property_category = \"Outdoor\"\n",
    "GROUP BY \n",
    "    ---- # [Insert Dataset]\n",
    "ORDER BY \n",
    "    hour_of_call ---; # [Insert Direction (ASC or DESC)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99655b2-da92-4fdb-a147-afbede5d5ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check what results you got!\n",
    "\n",
    "hour_of_call_outdoorcategory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90fded-2729-4a97-b5e2-1f939f13a666",
   "metadata": {},
   "source": [
    "Next up, have a go at producing a breakdown per incident group, for those reported within a dwelling (property category), using your knowledge of SQL and magic commands to manipulate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646302a3-ab37-4217-a2fe-dcbbd0c38198",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery hour_of_call_dwellingcategory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1799f0-8e68-455c-9282-65e5262ccec0",
   "metadata": {},
   "source": [
    "## Section 3c: Basic Descriptive Statistics\n",
    "\n",
    "As we have already explored all of the available numerical variables for the given dataset, lets jump across to a slightly different dataset to explore this skill further. \n",
    "\n",
    "Using the staged prompts available, explore the dataset \"\n",
    "bigquery-public-data.noaa_hurricanes.hurricanes\", particularly exploring the numerical data and producing basic descriptive statistics for: \n",
    "\n",
    "- wmo_wind \n",
    "- wmo_pressure \n",
    "- usa_wind\n",
    "- usa_pressure\n",
    "- cma_presure \n",
    "\n",
    "Please check the solution sheet for our answer, however, like most programming, there will always be multiple ways to conduct this analysis! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f56db-17b9-4149-a18e-93f414da9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery hurricane_description\n",
    "SELECT \n",
    "    ----, # [Insert Variables here]\n",
    "FROM \n",
    "    bigquery-public-data.noaa_hurricanes.hurricanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d63a1e-3893-4c33-8cff-e0e8917dae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hurricane_description.------ # [Insert describe function]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b8411-850e-4753-8ebe-81d1a32dc0fe",
   "metadata": {},
   "source": [
    "## Section 3d: Building Cross Tabs \n",
    "Lets build some more complex crosstabs, for this we will explore the 'stop_code_description', and 'property_category'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd802637-5745-48f0-b9aa-0eb23aeb615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery crosstab_explore_data_stopcategory\n",
    "SELECT \n",
    "    -----, # [Insert Variables]\n",
    "FROM \n",
    "    bigquery-public-data.london_fire_brigade.fire_brigade_service_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0e005-c2a5-4449-baa2-75b74f3237e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab in Pandas \n",
    "## https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html\n",
    "pd.crosstab(\n",
    "    ------,\n",
    "    ------) # [Insert the two elements needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92382ba-46a0-498c-b592-017714a65f5f",
   "metadata": {},
   "source": [
    "Taking this further, we can now explore the breakdown between \"stop_code_description\" and \"property_type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bce3d6-e505-4c6c-831e-90fa53e4a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery crosstab_explore_data_stoptype\n",
    "SELECT \n",
    "    -----, # [Insert Variables]\n",
    "FROM \n",
    "    bigquery-public-data.london_fire_brigade.fire_brigade_service_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f54d6-b78e-4f45-a2b6-4a323caaf37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab in Pandas \n",
    "## https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html\n",
    "pd.crosstab(\n",
    "    ------,\n",
    "    ------) # [Insert the two elements needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f4211-96a9-4227-94ff-880ce3484373",
   "metadata": {},
   "source": [
    "## Section 4: Data Visualisation \n",
    "\n",
    "Once again using the results from Section 3b, we can create visualisations using matplotlib! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38dd0ea-5614-4ed9-a717-31a44f11ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chat 1: \n",
    "    # For this we will want to call hour of call vs incident number count \n",
    "plt.bar(hour_of_call_outdoorcategory.----, # [Call our X Variable]\n",
    "        hour_of_call_outdoorcategory.----) # [Call our Y variable]\n",
    "# Label our X and Y axis and Title \n",
    "plt.xlabel('----') # [Give a relevant X Label \n",
    "plt.ylabel('----') # [Give a relevant Y Label]\n",
    "plt.title('Number of Incidents recorded for Outdoor Callouts per Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d34a9a-c544-4a3a-83ea-d5a73bb18ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chat 2: \n",
    "    # For this we will want to call Incident Group vs incident number count "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799a1d6-0a17-47e9-b96b-55c08d31e492",
   "metadata": {},
   "source": [
    "## Extension\n",
    "\n",
    "If you would like to explore these skills and explore further, our suggestion is to rerun these exercises with the Hurricanes Dataset used within Section 3c. Focusing on variables such as 'mlc_class', 'mlc_wind' and 'mlc_pressure' and how this varies from other metrics such as nadi, usa and cma. These however will not have solutions here, but we will be happy to discuss them during the deep dive to help fuel your imagination! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c8d4c-9734-42b0-a847-9eadcf366cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
