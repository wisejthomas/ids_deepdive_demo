{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16d4665-a9e5-4c96-8ecb-33dc4c4bfeb0",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This demonstration page is to provide a learning scaffold for the upcoming IDS Deep Dive session, this is to be accompanied by a practical worksheet which users can complete at their own pace after this session. We encourage users to follow along with us within the session, and having a go at the various exercises within the parrellel worksheet following the session. \n",
    "\n",
    "## Important Note: \n",
    "We have arranged with Google for this Qwiki-labs enviornment to remain open until April 1st. Please note, this is only to be used to complete and engage with this demonstration, with any deviation having action taking against the account, with this in order to maintain the integrity of the platform. This means you can restart and complete this lab as many times as you would like, however please only explore the capabilities of bigquery & jupyter lab in line with this demonstration and practical and nothing else. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908795eb-fce4-43b8-937f-58d82d082962",
   "metadata": {},
   "source": [
    "## Section 0: Setup of Workbench Space\n",
    "\n",
    "To start this practical, we first must setup our workbench space within Qwiki-labs environment, this is a step one will not need to complete within the IDS environment, however for today's practical we will. For this we can follow the steps highlighted in Task 1 of the Lab. \n",
    "\n",
    "When we've followed all those steps, and we've reached Task 2, we can then import this repo from git, using the command\n",
    "\n",
    "<code> !git clone https://github.com/wisejthomas/ids_deepdive_demo </code>\n",
    "\n",
    "This will import this practical and demo into this workspace! \n",
    "\n",
    "### Important Definitions \n",
    "\n",
    "At this point, it is important to cover a few critical definitions:\n",
    "\n",
    "- **BigQuery** BigQuery is a fully managed, AI-ready data platform that helps you manage and analyze your data with built-in features like machine learning, search, geospatial analysis, and business intelligence. BigQuery's serverless architecture lets you use languages like SQL and Python to answer your organization's biggest questions with zero infrastructure management.\n",
    "\n",
    "- **JupyterLab** JupyterLab is a highly extensible, feature-rich notebook authoring application and editing environment, and is a part of Project Jupyter, a large umbrella project centered around the goal of providing tools (and standards) for interactive computing with computational notebooks.\n",
    "\n",
    "- **Vertex AI Workbench instance** Vertex AI Workbench instances are Jupyter notebook-based development environments on Google Cloud for the entire data science workflow. Vertex AI Workbench instances are prepackaged with JupyterLab. Vertex AI Workbench instances have integrations and features can make it easier to access your data, process data faster, schedule notebook runs, and more.\n",
    "\n",
    "For most of these methods, we will use a Python JupyterLab Kernel. In the Jupyter architecture, kernels are separate processes started by the server that run your code in different programming languages and environments. We will use the IPython Jupyter Kernel that comes prepackaged with Vertex AI Workbench Instances. This will allow us to execute Python code in this notebook interactively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315a909-d60c-409d-8dde-444b0024120b",
   "metadata": {},
   "source": [
    "## Section 1: Navigating Data in BigQuery Studio \n",
    "\n",
    "To explore that data available to you within your project space, we can use the BigQuery Studio space. This is a UI on Google Cloud, which allows your to view information such as column names and descriptions, as well as a preview of the data. \n",
    "\n",
    "To access this UI you can select this link \n",
    "- Link: https://console.cloud.google.com/bigquery \n",
    "- Navigate via the UI to BigQuery >> Studio\n",
    "\n",
    "Here we can begin to explore the public data, in particular, the London Fire Brigade call outs in 2017. We can explore this data by following these steps: \n",
    "\n",
    "- Select project \"bigquery-public-data\" (if you don't see it, don't panic, just search for \"*London*\" in the search bar and it should appear!)\n",
    "    - Locate and select the dataset: \"london_fire_brigade\"\n",
    "        - Select table: \"fire_brigade_service_calls\"\n",
    "            - We can then preview a sample of this table, as well as view information such as column descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48adf00e-360a-4ea0-bbb9-ab175743b4a4",
   "metadata": {},
   "source": [
    "## Section 2: Introducing Jupyter Lab for Python \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df448252-e204-48ce-8cbc-f7cd13f49e6a",
   "metadata": {},
   "source": [
    "### Section 2a: Package Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd3044-b7cb-4cd9-8a7c-4e7b5b3a91e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# here the package is bigframes https://pypi.org/project/bigframes/\n",
    "import sys\n",
    "!{sys.executable} -m pip install bigframes | grep -v 'already satisfied'\n",
    "\n",
    "import bigframes.pandas as bpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# import warnings filter & ignore all future warnings\n",
    "# this is for teaching purposes only, to avoid FutureWarnings to do with bigframe compiler implementation\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302d756-e5e6-4aa6-accc-4fc1680afeae",
   "metadata": {},
   "source": [
    "## Section 3: Supercharging Python with \"BigFrames\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be041c8-5398-4e99-8537-531b91dbd376",
   "metadata": {},
   "source": [
    "### Section 3a: Load in Data\n",
    "For today's demonstration we will be exploring the Google Dataset around London Fire Brigade call outs in 2017. This dataset has been selected due to its similarity in variable type to the data. \n",
    "\n",
    "To demonstrate the potential power when using BigFrames, we will first load in the data, before using magic commands to manipulate the data then creating descriptive statistics and running simple crosstabs to gain a better understanding of the data available. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556fabc-4d7c-481a-b0bc-a5c00d967d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from BigQuery\n",
    "print(\"step 1-of-3 :: loading data from BigQuery\")\n",
    "query_or_table = \"bigquery-public-data.london_fire_brigade.fire_brigade_service_calls\"\n",
    "bq_df = bpd.read_gbq(query_or_table, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a55fa-6036-4d68-9c99-84351cd0cd02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets double check our column names \n",
    "list(bq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac1283-d07d-4e90-a94e-e6032040a401",
   "metadata": {},
   "source": [
    "### Section 3b: Using Magic Commands to Manipulate Data\n",
    "In order to improve the effeciency of writting queries and performing particular tasks, BigQuery has developed \"cell magics\" to make it easy to execute SQL queries. There are two BigQuery \"cell magics\": \n",
    "\n",
    "> %%bigquery\n",
    "- Behind the scenes, the %%bigquery magic command uses the BigQuery client library for Python to run the given query\n",
    "- Then convert the results to a pandas DataFrame\n",
    "- Then display results.\n",
    "\n",
    "> %%bigquery my_pandas_data_frame\n",
    "- Behind the scenes, the %%bigquery magic command uses the BigQuery client library for Python to run the given query\n",
    "- Then convert the results to a pandas DataFrame\n",
    "- Then save the pandas DataFrame to the variable my_pandas_data_frame\n",
    "\n",
    "Let us first of all consider, how many call outs, for the fire service were made by hour during 2017. We can assign this to the data frame *hour_of_call_incident_count* - we will come back to this later when we look to visualise these results! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d911611-bca0-4972-b7c1-cab9f56e7fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery hour_of_call_incident_count\n",
    "SELECT \n",
    "    hour_of_call,\n",
    "    COUNT(DISTINCT incident_number) as incident_number_count\n",
    "FROM \n",
    "    bigquery-public-data.london_fire_brigade.fire_brigade_service_calls\n",
    "GROUP BY \n",
    "    hour_of_call\n",
    "ORDER BY \n",
    "    hour_of_call ASC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc0109-df19-4252-a573-4030499bbe7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the meantime however, we can view the first five hours of the day!\n",
    "hour_of_call_incident_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331476e-af1f-46ab-974f-43dcfa4ec24f",
   "metadata": {},
   "source": [
    "### Section 3c: Basic Descriptive Statistics\n",
    "\n",
    "Exploring the basic descriptive statistics of any given dataset is critical to beginning to understand its components and what you, as an analyst, can achieve with it. Luckily, Python includes a basic descriptive function, <code> .describe() </code> , which can be applied simply to BigFrame. \n",
    "\n",
    "For this we will explore the numerical variables within our dataset, in particular the hour of call, number of pumps attending and the number of stations with pumps attending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88047715-5809-4482-9933-a0d009da36ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery fire_numerical_describe\n",
    "SELECT \n",
    "    hour_of_call,\n",
    "    num_stations_with_pumps_attending,\n",
    "    num_pumps_attending\n",
    "FROM \n",
    "    bigquery-public-data.london_fire_brigade.fire_brigade_service_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15227033-c0c5-4d59-a016-de52dc808fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the describe function to explore the core basic descriptive statistics\n",
    "fire_numerical_describe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ae235-3883-4cb6-956a-524c913c05a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 3d: Building Cross Tabs \n",
    "\n",
    "Cross tabs can be used to examine the relationship between two categorical variables. This can be extremely beneficial to understand the frequency of different occuring factors and to begin to further understand the data presented. \n",
    "\n",
    "When building cross tabs, the easiest method for medium sized datasets at present is utilizing Pandas, on your local memory. This is because at present the same function is yet to be fully available within the BigFrames library. \n",
    "\n",
    "For this example, we will look at the relationship between Incident Group and Property Category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1933e10-09b9-4a00-90b4-625d492fcbd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery crosstab_explore_data\n",
    "SELECT \n",
    "    incident_group,\n",
    "    property_category\n",
    "FROM \n",
    "    bigquery-public-data.london_fire_brigade.fire_brigade_service_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8e094-9860-4f7b-ae7f-a0ccff7d763b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crosstab in Pandas \n",
    "## https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html\n",
    "pd.crosstab(\n",
    "    crosstab_explore_data.incident_group, \n",
    "    crosstab_explore_data.property_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f407a2-fa4b-4869-aa67-0c88c2ad05b6",
   "metadata": {},
   "source": [
    "## Section 4: Visualising your Data in Python\n",
    "Lets return to our number of incident per hour, from Section 3b. Lets plot this using matplotlib.\n",
    "\n",
    "When using matplotlib we can simply highlight our X and Y variables respectively. In this case, we would like to create a bar plot, between the \"hour of calls\" and the \"number of incidents\" in that time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbe36b-e7fa-4ef6-a931-3d23421810bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bar Chart Call X = Hour of Call, Y = Incident Number Count \n",
    "plt.bar(hour_of_call_incident_count.hour_of_call, hour_of_call_incident_count.incident_number_count)\n",
    "# Label our X and Y axis and Title \n",
    "plt.xlabel('Hour of Call')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.title('Number of Incidents recorded per Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f88a0-fb29-44e9-8ae7-ca4e12868f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
